{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e8fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sleep Health & Lifestyle Analysis - Data Preprocessing & Feature Engineering\n",
    "# Part 2: Cleaning, Transformation, and Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "367a7a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89b22f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Shape: (400, 13)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===========================\n",
    "# 1.A. LOAD DATA\n",
    "# ===========================\n",
    "\n",
    "df = pd.read_csv(\"D:\\\\GIT_HUB\\\\12_Final_Projects_of_all\\\\01_Analysis\\Dataset\\\\sleep_health_lifestyle_dataset.csv\")\n",
    "print(\"Original Dataset Shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01a70f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===========================\n",
    "# 1.A. LOAD DATA\n",
    "# ===========================\n",
    "\n",
    "df = pd.read_csv(\"D:\\\\GIT_HUB\\\\12_Final_Projects_of_all\\\\01_Analysis\\Dataset\\\\sleep_health_lifestyle_dataset.csv\")\n",
    "print(\"Original Dataset Shape:\", df.shape)\n",
    "\n",
    "# ========================================================\n",
    "# 1.B. COLUMN RENAMING (FROM PART 1) ### [NEWLY ADDED] ###\n",
    "# ========================================================\n",
    "# This is critical to prevent KeyErrors in the steps below.\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RENAMING COLUMNS FOR CONSISTENCY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "column_rename_map = {\n",
    "    'Person ID': 'Person_ID',\n",
    "    'Sleep Duration (hours)': 'Sleep Duration',\n",
    "    'Quality of Sleep (scale: 1-10)': 'Quality of Sleep',\n",
    "    'Physical Activity Level (minutes/day)': 'Physical Activity Level',\n",
    "    'Stress Level (scale: 1-10)': 'Stress Level',\n",
    "    'Blood Pressure (systolic/diastolic)': 'Blood Pressure',\n",
    "    'Heart Rate (bpm)': 'Heart Rate'\n",
    "}\n",
    "\n",
    "df = df.rename(columns=column_rename_map)\n",
    "print(\"Columns successfully renamed.\")\n",
    "\n",
    "# Create a copy for preprocessing\n",
    "df_processed = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1dcfd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RENAMING COLUMNS FOR CONSISTENCY\n",
      "============================================================\n",
      "Columns successfully renamed.\n",
      "\n",
      "============================================================\n",
      "IMPUTING MISSING 'Sleep Disorder' VALUES\n",
      "============================================================\n",
      "Found 290 missing 'Sleep Disorder' values.\n",
      "✓ Created 'SleepDisorder_Imputed' flag column.\n",
      "✓ Filled 290 NaNs with 'None'.\n",
      "\n",
      "✓ Preprocessing copy created. Ready to proceed with Part 2.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ========================================================\n",
    "# 1.B. COLUMN RENAMING (FROM PART 1)\n",
    "# ========================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RENAMING COLUMNS FOR CONSISTENCY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "column_rename_map = {\n",
    "    'Person ID': 'Person_ID',\n",
    "    'Sleep Duration (hours)': 'Sleep Duration',\n",
    "    'Quality of Sleep (scale: 1-10)': 'Quality of Sleep',\n",
    "    'Physical Activity Level (minutes/day)': 'Physical Activity Level',\n",
    "    'Stress Level (scale: 1-10)': 'Stress Level',\n",
    "    'Blood Pressure (systolic/diastolic)': 'Blood Pressure',\n",
    "    'Heart Rate (bpm)': 'Heart Rate'\n",
    "}\n",
    "\n",
    "df = df.rename(columns=column_rename_map)\n",
    "print(\"Columns successfully renamed.\")\n",
    "\n",
    "# ========================================================\n",
    "# 1.C. HANDLE MISSING TARGET (THE \"TWIST\" FIX)\n",
    "# ========================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"IMPUTING MISSING 'Sleep Disorder' VALUES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check for NaNs\n",
    "missing_count = df['Sleep Disorder'].isnull().sum()\n",
    "print(f\"Found {missing_count} missing 'Sleep Disorder' values.\")\n",
    "\n",
    "if missing_count > 0:\n",
    "    # 1. Create the \"Imputation Flag\" feature\n",
    "    # This is our \"expert twist\"\n",
    "    df['SleepDisorder_Imputed'] = df['Sleep Disorder'].isnull().astype(int)\n",
    "    \n",
    "    # 2. Fill NaNs with 'None' (as you requested)\n",
    "    df['Sleep Disorder'] = df['Sleep Disorder'].fillna('None')\n",
    "    \n",
    "    print(f\"✓ Created 'SleepDisorder_Imputed' flag column.\")\n",
    "    print(f\"✓ Filled {missing_count} NaNs with 'None'.\")\n",
    "else:\n",
    "    # If no NaNs, still create the flag column (all 0s)\n",
    "    df['SleepDisorder_Imputed'] = 0\n",
    "    print(\"✓ No missing 'Sleep Disorder' values found. Flag column created.\")\n",
    "\n",
    "# ========================================================\n",
    "# 1.D. CREATE DATASET COPIES\n",
    "# ========================================================\n",
    "# Now we create the copy for preprocessing, which includes our fix.\n",
    "# This single, unified dataset will work for BOTH Power BI and ML.\n",
    "\n",
    "df_processed = df.copy()\n",
    "\n",
    "print(\"\\n✓ Preprocessing copy created. Ready to proceed with Part 2.\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# (The rest of your script, Sections 2-9, remains *exactly* the same)\n",
    "# -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dd8c47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PROCESSING BLOOD PRESSURE\n",
      "============================================================\n",
      "Blood Pressure Category Distribution:\n",
      "BP_Category\n",
      "Normal         152\n",
      "Elevated       138\n",
      "High_Stage1    105\n",
      "High_Stage2      5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===========================\n",
    "# 2. BLOOD PRESSURE PROCESSING\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PROCESSING BLOOD PRESSURE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Split Blood Pressure into Systolic and Diastolic\n",
    "# This now works because we renamed the column to 'Blood Pressure'\n",
    "df_processed[['Systolic_BP', 'Diastolic_BP']] = df_processed['Blood Pressure'].str.split('/', expand=True)\n",
    "df_processed['Systolic_BP'] = pd.to_numeric(df_processed['Systolic_BP'])\n",
    "df_processed['Diastolic_BP'] = pd.to_numeric(df_processed['Diastolic_BP'])\n",
    "\n",
    "# Create Blood Pressure categories based on medical standards\n",
    "def categorize_bp(systolic, diastolic):\n",
    "    if systolic < 120 and diastolic < 80:\n",
    "        return 'Normal'\n",
    "    elif systolic < 130 and diastolic < 80:\n",
    "        return 'Elevated'\n",
    "    elif systolic < 140 or diastolic < 90:\n",
    "        return 'High_Stage1'\n",
    "    else:\n",
    "        return 'High_Stage2'\n",
    "\n",
    "df_processed['BP_Category'] = df_processed.apply(\n",
    "    lambda x: categorize_bp(x['Systolic_BP'], x['Diastolic_BP']), axis=1\n",
    ")\n",
    "\n",
    "print(\"Blood Pressure Category Distribution:\")\n",
    "print(df_processed['BP_Category'].value_counts())\n",
    "\n",
    "# Drop original Blood Pressure column\n",
    "df_processed = df_processed.drop('Blood Pressure', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da185d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FEATURE ENGINEERING\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===========================\n",
    "# 3. FEATURE ENGINEERING\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Sleep Efficiency Score (Custom metric)\n",
    "# These columns are now guaranteed to exist\n",
    "df_processed['Sleep_Efficiency'] = (df_processed['Sleep Duration'] / 8) * df_processed['Quality of Sleep']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54dd6ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in Health_Risk_Score: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Health Risk Score (Composite metric)\n",
    "### [CORRECTED] ###\n",
    "# Added 'Underweight': 1 to prevent NaNs.\n",
    "# Mapped 'Underweight', 'Normal', and 'Normal Weight' to 1 (low risk).\n",
    "bmi_risk_map = {\n",
    "    'Underweight': 1,\n",
    "    'Normal': 1,\n",
    "    'Normal Weight': 1,\n",
    "    'Overweight': 2,\n",
    "    'Obese': 3\n",
    "}\n",
    "\n",
    "df_processed['Health_Risk_Score'] = (\n",
    "    df_processed['Stress Level'] * 0.3 +\n",
    "    (10 - df_processed['Physical Activity Level'] / 10) * 0.3 +\n",
    "    (df_processed['Heart Rate'] / 10) * 0.2 +\n",
    "    (df_processed['BMI Category'].map(bmi_risk_map)) * 0.2\n",
    ")\n",
    "\n",
    "# Check for any NaNs created by the map (should be 0)\n",
    "print(f\"NaNs in Health_Risk_Score: {df_processed['Health_Risk_Score'].isnull().sum()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a012160",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Age Groups\n",
    "def categorize_age(age):\n",
    "    if age < 30:\n",
    "        return 'Young_Adult'\n",
    "    elif age < 45:\n",
    "        return 'Middle_Age'\n",
    "    elif age < 60:\n",
    "        return 'Senior'\n",
    "    else:\n",
    "        return 'Elderly'\n",
    "\n",
    "df_processed['Age_Group'] = df_processed['Age'].apply(categorize_age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a83582f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Sleep Duration Category\n",
    "def categorize_sleep_duration(duration):\n",
    "    if duration < 6:\n",
    "        return 'Insufficient'\n",
    "    elif duration < 7:\n",
    "        return 'Below_Optimal'\n",
    "    elif duration <= 9:\n",
    "        return 'Optimal'\n",
    "    else:\n",
    "        return 'Excessive'\n",
    "\n",
    "df_processed['Sleep_Duration_Category'] = df_processed['Sleep Duration'].apply(categorize_sleep_duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01b2d782",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Activity Level Category\n",
    "def categorize_activity(minutes):\n",
    "    if minutes < 30:\n",
    "        return 'Sedentary'\n",
    "    elif minutes < 60:\n",
    "        return 'Moderate'\n",
    "    else:\n",
    "        return 'Active'\n",
    "\n",
    "df_processed['Activity_Category'] = df_processed['Physical Activity Level'].apply(categorize_activity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2aae492",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. Stress Category\n",
    "def categorize_stress(stress):\n",
    "    if stress <= 3:\n",
    "        return 'Low'\n",
    "    elif stress <= 6:\n",
    "        return 'Moderate'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "df_processed['Stress_Category'] = df_processed['Stress Level'].apply(categorize_stress)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1f28d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7. Heart Rate Category\n",
    "def categorize_heart_rate(hr):\n",
    "    if hr < 60:\n",
    "        return 'Low'\n",
    "    elif hr <= 100:\n",
    "        return 'Normal'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "df_processed['Heart_Rate_Category'] = df_processed['Heart Rate'].apply(categorize_heart_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd9be44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8. Daily Steps Category (Based on fitness goals)\n",
    "def categorize_steps(steps):\n",
    "    if steps < 5000:\n",
    "        return 'Sedentary'\n",
    "    elif steps < 7500:\n",
    "        return 'Low_Active'\n",
    "    elif steps < 10000:\n",
    "        return 'Somewhat_Active'\n",
    "    else:\n",
    "        return 'Active'\n",
    "\n",
    "df_processed['Steps_Category'] = df_processed['Daily Steps'].apply(categorize_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d330f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 9. Sleep Quality Category\n",
    "def categorize_sleep_quality(quality):\n",
    "    if quality <= 4:\n",
    "        return 'Poor'\n",
    "    elif quality <= 6:\n",
    "        return 'Fair'\n",
    "    elif quality <= 8:\n",
    "        return 'Good'\n",
    "    else:\n",
    "        return 'Excellent'\n",
    "\n",
    "df_processed['Sleep_Quality_Category'] = df_processed['Quality of Sleep'].apply(categorize_sleep_quality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "690e4de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Features Created:\n",
      "  - Sleep_Efficiency\n",
      "  - Health_Risk_Score\n",
      "  - Age_Group\n",
      "  - Sleep_Duration_Category\n",
      "  - Activity_Category\n",
      "  - Stress_Category\n",
      "  - Heart_Rate_Category\n",
      "  - Steps_Category\n",
      "  - Sleep_Quality_Category\n",
      "  - Has_Sleep_Disorder\n",
      "  - Systolic_BP\n",
      "  - Diastolic_BP\n",
      "  - BP_Category\n"
     ]
    }
   ],
   "source": [
    "# 10. Binary Sleep Disorder Flag\n",
    "df_processed['Has_Sleep_Disorder'] = (df_processed['Sleep Disorder'] != 'None').astype(int)\n",
    "\n",
    "print(\"\\nNew Features Created:\")\n",
    "new_features = ['Sleep_Efficiency', 'Health_Risk_Score', 'Age_Group',\n",
    "                'Sleep_Duration_Category', 'Activity_Category', 'Stress_Category',\n",
    "                'Heart_Rate_Category', 'Steps_Category', 'Sleep_Quality_Category',\n",
    "                'Has_Sleep_Disorder', 'Systolic_BP', 'Diastolic_BP', 'BP_Category']\n",
    "for feature in new_features:\n",
    "    print(f\"  - {feature}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a16b6c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ENCODING CATEGORICAL VARIABLES\n",
      "============================================================\n",
      "Dataset shape after encoding: (400, 38)\n",
      "Total features: 38\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===========================\n",
    "# 4. HANDLE CATEGORICAL VARIABLES\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ENCODING CATEGORICAL VARIABLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create a copy for ML\n",
    "df_ml = df_processed.copy()\n",
    "\n",
    "# Label Encoding for ordinal variables\n",
    "label_encoders = {}\n",
    "\n",
    "### [CORRECTED] ###\n",
    "# Added 'Underweight' to the BMI Category list to prevent NaNs.\n",
    "ordinal_features = {\n",
    "    'BMI Category': ['Underweight', 'Normal', 'Normal Weight', 'Overweight', 'Obese'],\n",
    "    'Sleep_Duration_Category': ['Insufficient', 'Below_Optimal', 'Optimal', 'Excessive'],\n",
    "    'Activity_Category': ['Sedentary', 'Moderate', 'Active'],\n",
    "    'Stress_Category': ['Low', 'Moderate', 'High'],\n",
    "    'Sleep_Quality_Category': ['Poor', 'Fair', 'Good', 'Excellent'],\n",
    "    'BP_Category': ['Normal', 'Elevated', 'High_Stage1', 'High_Stage2']\n",
    "}\n",
    "\n",
    "for feature, order in ordinal_features.items():\n",
    "    # Create a mapping based on the order\n",
    "    category_map = {val: idx for idx, val in enumerate(order)}\n",
    "    df_ml[feature + '_Encoded'] = df_ml[feature].map(category_map)\n",
    "    # Check for any new NaNs\n",
    "    if df_ml[feature + '_Encoded'].isnull().sum() > 0:\n",
    "        print(f\"Warning: NaNs created in {feature}_Encoded. Check map and data.\")\n",
    "\n",
    "# One-Hot Encoding for nominal variables\n",
    "nominal_features = ['Gender', 'Occupation', 'Age_Group',\n",
    "                    'Heart_Rate_Category', 'Steps_Category']\n",
    "\n",
    "# We explicitly DO NOT one-hot encode 'Sleep Disorder' here\n",
    "# as it is our multi-class target variable.\n",
    "\n",
    "df_ml = pd.get_dummies(df_ml, columns=nominal_features, prefix=nominal_features, drop_first=True)\n",
    "\n",
    "print(f\"Dataset shape after encoding: {df_ml.shape}\")\n",
    "print(f\"Total features: {df_ml.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "411699f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "OUTLIER DETECTION (IQR Method)\n",
      "============================================================\n",
      "Age: 3 outliers\n",
      "Sleep Duration: 0 outliers\n",
      "Physical Activity Level: 0 outliers\n",
      "Stress Level: 0 outliers\n",
      "Heart Rate: 0 outliers\n",
      "Daily Steps: 0 outliers\n",
      "Systolic_BP: 0 outliers\n",
      "Diastolic_BP: 0 outliers\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# 5. OUTLIER DETECTION\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"OUTLIER DETECTION (IQR Method)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# This list is correct, as it's the original numerical features\n",
    "numerical_features = ['Age', 'Sleep Duration', 'Physical Activity Level',\n",
    "                      'Stress Level', 'Heart Rate', 'Daily Steps',\n",
    "                      'Systolic_BP', 'Diastolic_BP']\n",
    "\n",
    "def detect_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return len(outliers)\n",
    "\n",
    "for feature in numerical_features:\n",
    "    outlier_count = detect_outliers_iqr(df_processed, feature)\n",
    "    print(f\"{feature}: {outlier_count} outliers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e712998c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FEATURE SCALING\n",
      "============================================================\n",
      "Numerical features scaled using StandardScaler\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===========================\n",
    "# 6. FEATURE SCALING (for ML)\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FEATURE SCALING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Select numerical features to scale\n",
    "features_to_scale = ['Age', 'Sleep Duration', 'Physical Activity Level',\n",
    "                     'Stress Level', 'Heart Rate', 'Daily Steps',\n",
    "                     'Systolic_BP', 'Diastolic_BP', 'Sleep_Efficiency', 'Health_Risk_Score']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_ml[features_to_scale] = scaler.fit_transform(df_ml[features_to_scale])\n",
    "\n",
    "print(\"Numerical features scaled using StandardScaler\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6bd623f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PREPARING ML DATASETS\n",
      "============================================================\n",
      "\n",
      "Sleep Quality Prediction Dataset:\n",
      "  Features shape: (400, 27)\n",
      "  Target (regression) shape: (400,)\n",
      "  Target (classification) shape: (400,)\n",
      "\n",
      "Sleep Disorder Prediction Dataset:\n",
      "  Features shape: (400, 27)\n",
      "  Target (multi-class) shape: (400,)\n",
      "  Target (binary) shape: (400,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===========================\n",
    "# 7. PREPARE DATASETS FOR DIFFERENT ML TASKS\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PREPARING ML DATASETS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# --- Define Target (y) variables ---\n",
    "# We get these from the *unscaled* processed DataFrame\n",
    "y_quality_regression = df_processed['Quality of Sleep']\n",
    "y_quality_classification = df_processed['Sleep_Quality_Category']\n",
    "y_disorder_multiclass = df_processed['Sleep Disorder']\n",
    "y_disorder_binary = df_processed['Has_Sleep_Disorder']\n",
    "\n",
    "\n",
    "# --- Define Feature (X) sets ---\n",
    "\n",
    "# Task 1: Sleep Quality Prediction (Regression/Classification)\n",
    "# We drop the Person_ID and all target-related columns\n",
    "# (Sleep Disorder AND Sleep Quality)\n",
    "drop_cols_quality = [\n",
    "    'Person_ID',\n",
    "    'Quality of Sleep', 'Sleep_Quality_Category', 'Sleep_Quality_Category_Encoded',\n",
    "    'Sleep Disorder', 'Has_Sleep_Disorder'\n",
    "]\n",
    "# We also drop the original categorical strings that have been encoded\n",
    "for cat in list(ordinal_features.keys()) + ['Gender', 'Occupation', 'Age_Group', 'Heart_Rate_Category', 'Steps_Category']:\n",
    "    if cat in df_ml.columns:\n",
    "        drop_cols_quality.append(cat)\n",
    "\n",
    "X_quality = df_ml.drop(columns=drop_cols_quality, errors='ignore')\n",
    "\n",
    "\n",
    "# Task 2: Sleep Disorder Prediction (Multi-class/Binary Classification)\n",
    "### [CRITICAL FIX: PREVENTING DATA LEAKAGE] ###\n",
    "# We must ALSO drop the 'Quality of Sleep' columns.\n",
    "# Knowing sleep quality is 'Poor' is a direct leak for predicting 'Insomnia'.\n",
    "drop_cols_disorder = [\n",
    "    'Person_ID',\n",
    "    'Sleep Disorder', 'Has_Sleep_Disorder',\n",
    "    'Quality of Sleep', 'Sleep_Quality_Category', 'Sleep_Quality_Category_Encoded'\n",
    "]\n",
    "# Drop original categorical strings\n",
    "for cat in list(ordinal_features.keys()) + ['Gender', 'Occupation', 'Age_Group', 'Heart_Rate_Category', 'Steps_Category']:\n",
    "    if cat in df_ml.columns:\n",
    "        drop_cols_disorder.append(cat)\n",
    "        \n",
    "X_disorder = df_ml.drop(columns=drop_cols_disorder, errors='ignore')\n",
    "\n",
    "\n",
    "print(f\"\\nSleep Quality Prediction Dataset:\")\n",
    "print(f\"  Features shape: {X_quality.shape}\")\n",
    "print(f\"  Target (regression) shape: {y_quality_regression.shape}\")\n",
    "print(f\"  Target (classification) shape: {y_quality_classification.shape}\")\n",
    "\n",
    "print(f\"\\nSleep Disorder Prediction Dataset:\")\n",
    "print(f\"  Features shape: {X_disorder.shape}\")\n",
    "print(f\"  Target (multi-class) shape: {y_disorder_multiclass.shape}\")\n",
    "print(f\"  Target (binary) shape: {y_disorder_binary.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7239b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAIN-TEST SPLIT COMPLETED\n",
      "============================================================\n",
      "Sleep Quality (Reg) - Train: 320, Test: 80\n",
      "Sleep Disorder (Multi) - Train: 320, Test: 80\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===========================\n",
    "# 8. TRAIN-TEST SPLIT\n",
    "# ===========================\n",
    "\n",
    "# For Sleep Quality Prediction (Regression)\n",
    "X_train_q_reg, X_test_q_reg, y_train_q_reg, y_test_q_reg = train_test_split(\n",
    "    X_quality, y_quality_regression, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# For Sleep Disorder Prediction (Multi-class)\n",
    "X_train_d_multi, X_test_d_multi, y_train_d_multi, y_test_d_multi = train_test_split(\n",
    "    X_disorder, y_disorder_multiclass, test_size=0.2, random_state=42,\n",
    "    stratify=y_disorder_multiclass # Stratify is crucial here\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAIN-TEST SPLIT COMPLETED\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Sleep Quality (Reg) - Train: {X_train_q_reg.shape[0]}, Test: {X_test_q_reg.shape[0]}\")\n",
    "print(f\"Sleep Disorder (Multi) - Train: {X_train_d_multi.shape[0]}, Test: {X_test_d_multi.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4803689b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAVING PROCESSED DATASETS\n",
      "============================================================\n",
      "✓ Processed data for visualization saved: sleep_health_processed_for_viz.csv\n",
      "✓ Full ML-ready data saved: sleep_health_ml_ready_full.csv\n",
      "✓ Quality model feature names saved: feature_names_quality.csv\n",
      "✓ Disorder model feature names saved: feature_names_disorder.csv\n",
      "\n",
      "============================================================\n",
      "PREPROCESSING COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Summary:\n",
      "- Original features: 14\n",
      "- Engineered features: 13\n",
      "- Final ML features (Quality model): 27\n",
      "- Final ML features (Disorder model): 27\n",
      "- Records: 400\n",
      "\n",
      "Files Created:\n",
      "1. sleep_health_processed_for_viz.csv (for Power BI / Tableau)\n",
      "2. sleep_health_ml_ready_full.csv (for ML notebooks)\n",
      "3. feature_names_quality.csv (feature reference)\n",
      "4. feature_names_disorder.csv (feature reference)\n",
      "\n",
      "Ready for:\n",
      "✓ Machine Learning Model Development\n",
      "✓ Power BI Dashboard Creation\n",
      "✓ Advanced Statistical Analysis\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===========================\n",
    "# 9. SAVE PROCESSED DATA\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAVING PROCESSED DATASETS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save processed data for Power BI / Tableau\n",
    "# D:\\\\GIT_HUB\\\\12_Final_Projects_of_all\\\\01_Analysis\\\\Dataset\\\\\n",
    "# This is the human-readable version *before* scaling and one-hot encoding\n",
    "df_processed.to_csv('D:\\\\GIT_HUB\\\\12_Final_Projects_of_all\\\\01_Analysis\\\\Dataset\\\\sleep_health_processed_for_viz.csv', index=False)\n",
    "# df_processed.to_csv('sleep_health_processed_for_viz.csv', index=False)\n",
    "print(\"✓ Processed data for visualization saved: sleep_health_processed_for_viz.csv\")\n",
    "\n",
    "# Save the final ML-ready dataset (with all features/targets)\n",
    "# This is useful for notebooks\n",
    "df_ml.to_csv('D:\\\\GIT_HUB\\\\12_Final_Projects_of_all\\\\01_Analysis\\\\Dataset\\\\sleep_health_ml_ready_full.csv', index=False)\n",
    "# df_ml.to_csv('sleep_health_ml_ready_full.csv', index=False)\n",
    "\n",
    "print(\"✓ Full ML-ready data saved: sleep_health_ml_ready_full.csv\")\n",
    "\n",
    "# Save feature names for later use\n",
    "feature_names_quality = X_quality.columns.tolist()\n",
    "pd.DataFrame({'feature': feature_names_quality}).to_csv('D:\\\\GIT_HUB\\\\12_Final_Projects_of_all\\\\01_Analysis\\\\Dataset\\\\feature_names_quality.csv', index=False)\n",
    "# pd.DataFrame({'feature': feature_names_quality}).to_csv('feature_names_quality.csv', index=False)\n",
    "print(\"✓ Quality model feature names saved: feature_names_quality.csv\")\n",
    "\n",
    "feature_names_disorder = X_disorder.columns.tolist()\n",
    "pd.DataFrame({'feature': feature_names_disorder}).to_csv('D:\\\\GIT_HUB\\\\12_Final_Projects_of_all\\\\01_Analysis\\\\Dataset\\\\feature_names_disorder.csv', index=False)\n",
    "# pd.DataFrame({'feature': feature_names_disorder}).to_csv('feature_names_disorder.csv', index=False)\n",
    "\n",
    "print(\"✓ Disorder model feature names saved: feature_names_disorder.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PREPROCESSING COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\"\"\n",
    "Summary:\n",
    "- Original features: {df.shape[1]}\n",
    "- Engineered features: {len(new_features)}\n",
    "- Final ML features (Quality model): {X_quality.shape[1]}\n",
    "- Final ML features (Disorder model): {X_disorder.shape[1]}\n",
    "- Records: {df_ml.shape[0]}\n",
    "\n",
    "Files Created:\n",
    "1. sleep_health_processed_for_viz.csv (for Power BI / Tableau)\n",
    "2. sleep_health_ml_ready_full.csv (for ML notebooks)\n",
    "3. feature_names_quality.csv (feature reference)\n",
    "4. feature_names_disorder.csv (feature reference)\n",
    "\n",
    "Ready for:\n",
    "✓ Machine Learning Model Development\n",
    "✓ Power BI Dashboard Creation\n",
    "✓ Advanced Statistical Analysis\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a83fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3114",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
